{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "import chromadb\n",
    "import torch\n",
    "import pdfplumber\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoModel, AutoTokenizer, pipeline\n",
    "from PIL import ImageGrab\n",
    "\n",
    "# Step 1: Load Document Using LangChain\n",
    "pdf_path = \"sample_paper.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Save screenshot\n",
    "first_1000_chars = documents[0].page_content[:1000]\n",
    "print(first_1000_chars)  # Display first 1000 characters\n",
    "img = ImageGrab.grab()\n",
    "img.save(\"pdf_loader.png\")\n",
    "\n",
    "# Step 2: Apply Text Splitting Techniques\n",
    "latex_text = \"\"\"\\\\documentclass{article} ... \\\\end{document}\"\"\"  # Full LaTeX text\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "split_docs = splitter.create_documents([latex_text])\n",
    "\n",
    "# Save screenshot\n",
    "print(split_docs[0].page_content)  # Print first chunk\n",
    "img = ImageGrab.grab()\n",
    "img.save(\"code_splitter.png\")\n",
    "\n",
    "# Step 3: Embed Documents\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "query = \"How are you?\"\n",
    "query_embedding = embedding_model.embed_query(query)\n",
    "\n",
    "# Save screenshot\n",
    "print(query_embedding[:5])  # Print first 5 embedding numbers\n",
    "img = ImageGrab.grab()\n",
    "img.save(\"embedding.png\")\n",
    "\n",
    "# Step 4: Create and Configure Vector Databases\n",
    "chroma_db = Chroma.from_documents(split_docs, embedding_model)\n",
    "query = \"Smoking policy\"\n",
    "similar_results = chroma_db.similarity_search(query, k=5)\n",
    "\n",
    "# Save screenshot\n",
    "print(similar_results)  # Display retrieved results\n",
    "img = ImageGrab.grab()\n",
    "img.save(\"vectordb.png\")\n",
    "\n",
    "# Step 5: Develop a Retriever\n",
    "retriever = chroma_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
    "query = \"Email policy\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Save screenshot\n",
    "print(retrieved_docs)  # Print retrieved segments\n",
    "img = ImageGrab.grab()\n",
    "img.save(\"retriever.png\")\n",
    "\n",
    "# Step 6: Construct a QA Bot\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=HuggingFacePipeline.from_model_id(\n",
    "        model_id=\"mistralai/mixtral-8x7b-instruct-v01\",\n",
    "        task=\"text-generation\"\n",
    "    ),\n",
    "    retriever=retriever\n",
    ")\n",
    "query = \"What this paper is talking about?\"\n",
    "response = qa_chain.run(query)\n",
    "\n",
    "# Save screenshot\n",
    "print(response)  # Print the response\n",
    "img = ImageGrab.grab()\n",
    "img.save(\"QA_bot.png\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
