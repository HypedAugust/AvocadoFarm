{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "    # Replace all runs of whitespaces with no space\n",
    "    s = re.sub(r\"\\s+\", '', s)\n",
    "    # replace digits with no space\n",
    "    s = re.sub(r\"\\d\", '', s)\n",
    "\n",
    "    return s\n",
    "\n",
    "# 1 Language Modeling \n",
    "# 1-1 Tokenization \n",
    "from nltk.tokenize import word_tokenize\n",
    "def preprocess(words):\n",
    "    tokens=word_tokenize(words)\n",
    "    tokens=[preprocess_string(w)   for w in tokens]\n",
    "    return [w.lower()  for w in tokens if len(w)!=0 or not(w in string.punctuation) ]\n",
    "\n",
    "tokens=preprocess(song)\n",
    "\n",
    "# Create a frequency distribution of words\n",
    "fdist = nltk.FreqDist(tokens)\n",
    "fdist\n",
    "# 1-2 Unigram model \n",
    "# 1-3 Bigram model \n",
    "bigrams = nltk.bigrams(tokens)\n",
    "# 1-4 Trigram model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Feed Forward Neural Networks for lm\n",
    "# 2-1 Tokenization for FNN\n",
    "# Create a vocabulary from text tokens\n",
    "\n",
    "# tokenize the 'song' text using the provided tokenizer.\n",
    "# The map function applies the tokenizer to each word in the 'song' after splitting it.\n",
    "# The result is a list of tokens representing the words in the 'song'.\n",
    "tokenized_song = map(tokenizer, song.split())\n",
    "\n",
    "# Step 2: Vocabulary Building\n",
    "# The build_vocab_from_iterator function constructs a vocabulary from the tokenized text.\n",
    "# In this case, add a special token \"<unk>\" (unknown token) to handle out-of-vocabulary words.\n",
    "vocab = build_vocab_from_iterator(tokenized_song, specials=[\"<unk>\"])\n",
    "\n",
    "# Step 3: Set Default Index\n",
    "# Set the default index for the vocabulary to the index corresponding to the \"<unk>\" token.\n",
    "# This ensures that any unknown tokens in the future will be mapped to this index.\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "# 2-2 Indexing \n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "text_pipeline(song)[0:10]\n",
    "# 2-3 Embedding layers \n",
    "embedding_dim=20\n",
    "vocab_size=len(vocab)\n",
    "embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "\n",
    "# ALL \n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "tokens=tokenizer(song)\n",
    "\n",
    "# Create a vocabulary from text tokens\n",
    "\n",
    "# tokenize the 'song' text using the provided tokenizer.\n",
    "# The map function applies the tokenizer to each word in the 'song' after splitting it.\n",
    "# The result is a list of tokens representing the words in the 'song'.\n",
    "tokenized_song = map(tokenizer, song.split())\n",
    "\n",
    "# Step 2: Vocabulary Building\n",
    "# The build_vocab_from_iterator function constructs a vocabulary from the tokenized text.\n",
    "# In this case, add a special token \"<unk>\" (unknown token) to handle out-of-vocabulary words.\n",
    "vocab = build_vocab_from_iterator(tokenized_song, specials=[\"<unk>\"])\n",
    "\n",
    "# Step 3: Set Default Index\n",
    "# Set the default index for the vocabulary to the index corresponding to the \"<unk>\" token.\n",
    "# This ensures that any unknown tokens in the future will be mapped to this index.\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "\n",
    "index_to_token = vocab.get_itos()\n",
    "index_to_token[0]\n",
    "\n",
    "embedding_dim=20\n",
    "vocab_size=len(vocab)\n",
    "embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "for n in range(2): \n",
    "    embedding=embeddings(torch.tensor(n))\n",
    "    print(\"word\",index_to_token[n])\n",
    "    print(\"index\",n)\n",
    "    print( \"embedding\", embedding)\n",
    "    print(\"embedding shape\", embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Generating context target pairs \n",
    "\n",
    "CONTEXT_SIZE=2\n",
    "\n",
    "ngrams = [\n",
    "    (\n",
    "        [tokens[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
    "        tokens[i]\n",
    "    )\n",
    "    for i in range(CONTEXT_SIZE, len(tokens))\n",
    "]\n",
    "\n",
    "context, target=ngrams[0]\n",
    "print(\"context\",context,\"target\",target)\n",
    "print(\"context index\",vocab(context),\"target index\",vocab([target]))\n",
    "\n",
    "linear = nn.Linear(embedding_dim*CONTEXT_SIZE,128)\n",
    "\n",
    "my_embeddings=embeddings(torch.tensor(vocab(context)))\n",
    "my_embeddings.shape\n",
    "\n",
    "linear(my_embeddings)\n",
    "# 3-1 Batch Function \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CONTEXT_SIZE=3\n",
    "BATCH_SIZE=10\n",
    "EMBEDDING_DIM = 10\n",
    "\n",
    "def collate_batch(batch):\n",
    "    batch_size=len(batch)\n",
    "    context, target=[],[]\n",
    "    for i in range(CONTEXT_SIZE,batch_size):\n",
    "        target.append(vocab([batch[i]]))\n",
    "        context.append(vocab([batch[i-j-1] for j in range(CONTEXT_SIZE)]))\n",
    "\n",
    "    return   torch.tensor(context).to(device),  torch.tensor(target).to(device).reshape(-1)\n",
    "\n",
    "Padding=BATCH_SIZE-len(tokens)%BATCH_SIZE\n",
    "tokens_pad=tokens+tokens[0:Padding]\n",
    "\n",
    "dataloader = DataLoader(\n",
    "     tokens_pad, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "# 3-2 Multi class nn\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.context_size=context_size\n",
    "        self.embedding_dim=embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs)\n",
    "        embeds=torch.reshape( embeds, (-1,self.context_size * self.embedding_dim))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
