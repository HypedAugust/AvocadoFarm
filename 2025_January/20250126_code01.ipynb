{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 split data into predictor and target \n",
    "\n",
    "concrete_data_columns = concrete_data.columns \n",
    "\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column\n",
    "\n",
    "2 build nn network \n",
    "\n",
    "def regression_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Input(shape=(n_cols,)))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(1))\n",
    "\n",
    "\tmodel.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\treturn model\n",
    "d\n",
    "3 train and test the network \n",
    "model = regression_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(predictors_norm, target, validation_split=0.3, epochs=100, verbose=2)\n",
    "\n",
    "######\n",
    "\n",
    "# classifiction \n",
    "# 1 split data \n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) =mnist.load_data()\n",
    "\n",
    "# 2 flatten image into one dimensional vectors \n",
    "# flatten images into one-dimensional vector\n",
    "\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2] # find size of one-dimensional vector\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32') # flatten training images\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32') # flatten test images\n",
    "\n",
    "# normalize \n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# divide target variables into categories \n",
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]\n",
    "print(num_classes)\n",
    "\n",
    "# build NN\n",
    "\n",
    "# define classification model\n",
    "def classification_model():\n",
    "    # create model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(num_pixels,)))\n",
    "    model.add(Dense(num_pixels, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Fianlly, Train and Test \n",
    "# build the model\n",
    "model = classification_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
