{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f187f223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️  열기: https://www.gamedeveloper.com/\n",
      "   → 발견된 후보 링크: 1개\n",
      "▶️  열기: https://venturebeat.com/category/game-development/\n",
      "   → 발견된 후보 링크: 37개\n",
      "▶️  열기: https://www.developer-tech.com/categories/developer-gaming/\n",
      "   → 발견된 후보 링크: 5개\n",
      "✅ 수집된 기사 수: 13개\n",
      "✅ 'gdc_generative_ai_articles.xlsx' 에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# 1) 드라이버 준비\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--headless\")  # 창 안 띄우고 실행하려면 이 줄 주석 해제\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# 2) 크롤링 대상\n",
    "sites = [\n",
    "    # gamedeveloper.com: 'AI' 텍스트가 들어간 모든 <a> 태그에서 찾기\n",
    "    {\"url\": \"https://www.gamedeveloper.com/\", \"mode\": \"partial\"},  \n",
    "    # venturebeat: <h2><a>…</a></h2> 형태니까 CSS로 모두 긁어온 뒤 필터\n",
    "    {\"url\": \"https://venturebeat.com/category/game-development/\", \"mode\": \"css\", \"selector\": \"h2 a\"},  \n",
    "    # developer-tech: 역시 'AI' 텍스트 포함 <a> 태그에서 찾기\n",
    "    {\"url\": \"https://www.developer-tech.com/categories/developer-gaming/\", \"mode\": \"partial\"},  \n",
    "]\n",
    "\n",
    "# 3) 찾을 키워드\n",
    "KEYWORDS = [\"Generative AI\", \"AI\"]\n",
    "\n",
    "# 4) 결과 저장용\n",
    "seen = set()          # 중복 방지 (href 기준)\n",
    "results = []          # 최종 결과\n",
    "\n",
    "for site in sites:\n",
    "    print(f\"▶️  열기: {site['url']}\")\n",
    "    driver.get(site[\"url\"])\n",
    "    time.sleep(5)  # 동적 로딩 대기\n",
    "\n",
    "    elems = []\n",
    "    if site[\"mode\"] == \"css\":\n",
    "        elems = driver.find_elements(By.CSS_SELECTOR, site[\"selector\"])\n",
    "    else:  # mode == \"partial\"\n",
    "        for kw in KEYWORDS:\n",
    "            elems += driver.find_elements(By.PARTIAL_LINK_TEXT, kw)\n",
    "\n",
    "    print(f\"   → 발견된 후보 링크: {len(elems)}개\")\n",
    "\n",
    "    for a in elems:\n",
    "        title = a.text.strip()\n",
    "        href  = a.get_attribute(\"href\") or \"\"\n",
    "        if not href or href in seen:\n",
    "            continue\n",
    "        # 실제 키워드 포함 여부 재확인\n",
    "        if any(kw.lower() in title.lower() for kw in KEYWORDS):\n",
    "            seen.add(href)\n",
    "            results.append({\n",
    "                \"keyword\": next(kw for kw in KEYWORDS if kw.lower() in title.lower()),\n",
    "                \"title\":   title,\n",
    "                \"link\":    href\n",
    "            })\n",
    "\n",
    "driver.quit()\n",
    "print(f\"✅ 수집된 기사 수: {len(results)}개\")\n",
    "\n",
    "# 5) 엑셀 저장\n",
    "df = pd.DataFrame(results, columns=[\"keyword\", \"title\", \"link\"])\n",
    "out_file = \"gdc_generative_ai_articles.xlsx\"\n",
    "df.to_excel(out_file, index=False)\n",
    "print(f\"✅ '{out_file}' 에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e53f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️  Opening: https://www.gamedeveloper.com/\n",
      "   Found candidates: 1\n",
      "▶️  Opening: https://venturebeat.com/category/game-development/\n",
      "   Found candidates: 0\n",
      "▶️  Opening: https://www.developer-tech.com/categories/developer-gaming/\n",
      "   Found candidates: 5\n",
      "✅ GDC articles collected: 6\n",
      "✅ Saved to 'gdc_generative_ai_articles.xlsx'\n",
      "▶️  Opening: https://techcrunch.com/\n",
      "✅ TechCrunch articles collected: 0\n",
      "✅ Saved to 'techcrunch_ai_game_articles.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Merged script to:\n",
    "1. Collect \"Generative AI\" and \"AI\" articles from:\n",
    "   - gamedeveloper.com\n",
    "   - venturebeat.com/category/game-development/\n",
    "   - developer-tech.com/categories/developer-gaming/\n",
    "   Saves results to gdc_generative_ai_articles.xlsx\n",
    "\n",
    "2. Collect \"AI\" and \"Game\" articles from TechCrunch (https://techcrunch.com/)\n",
    "   Saves results to techcrunch_ai_game_articles.xlsx\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# 1) ChromeDriver 준비 & 옵션 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--headless\")  # Uncomment to run without opening a browser window\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# ===== Part 1: GDC sites (Generative AI & AI keywords) =====\n",
    "sites = [\n",
    "    {\"url\": \"https://www.gamedeveloper.com/\", \"mode\": \"partial\"},\n",
    "    {\"url\": \"https://venturebeat.com/category/game-development/\", \"mode\": \"css\", \"selector\": \"h2.article__title a\"},\n",
    "    {\"url\": \"https://www.developer-tech.com/categories/developer-gaming/\", \"mode\": \"partial\"},\n",
    "]\n",
    "KEYWORDS = [\"Generative AI\", \"AI\"]\n",
    "gdc_results = []\n",
    "seen = set()\n",
    "\n",
    "for site in sites:\n",
    "    print(f\"▶️  Opening: {site['url']}\")\n",
    "    driver.get(site[\"url\"])\n",
    "    time.sleep(5)  # Wait for dynamic content to load\n",
    "\n",
    "    elements = []\n",
    "    if site[\"mode\"] == \"css\":\n",
    "        elements = driver.find_elements(By.CSS_SELECTOR, site[\"selector\"])\n",
    "    else:\n",
    "        for kw in KEYWORDS:\n",
    "            elements += driver.find_elements(By.PARTIAL_LINK_TEXT, kw)\n",
    "\n",
    "    print(f\"   Found candidates: {len(elements)}\")\n",
    "    for a in elements:\n",
    "        title = a.text.strip()\n",
    "        href = a.get_attribute(\"href\") or \"\"\n",
    "        if not href or href in seen:\n",
    "            continue\n",
    "        if any(kw.lower() in title.lower() for kw in KEYWORDS):\n",
    "            seen.add(href)\n",
    "            keyword = next(kw for kw in KEYWORDS if kw.lower() in title.lower())\n",
    "            gdc_results.append({\"keyword\": keyword, \"title\": title, \"link\": href})\n",
    "\n",
    "print(f\"✅ GDC articles collected: {len(gdc_results)}\")\n",
    "df1 = pd.DataFrame(gdc_results, columns=[\"keyword\", \"title\", \"link\"])\n",
    "file1 = \"gdc_generative_ai_articles.xlsx\"\n",
    "df1.to_excel(file1, index=False)\n",
    "print(f\"✅ Saved to '{file1}'\")\n",
    "\n",
    "# ===== Part 2: TechCrunch (AI & Game keywords) =====\n",
    "print(\"▶️  Opening: https://techcrunch.com/\")\n",
    "driver.get(\"https://techcrunch.com/\")\n",
    "time.sleep(5)\n",
    "\n",
    "article_links = driver.find_elements(By.CSS_SELECTOR, \"h2.post-block__title a\")\n",
    "tc_results = []\n",
    "for a in article_links:\n",
    "    title = a.text.strip()\n",
    "    href = a.get_attribute(\"href\") or \"\"\n",
    "    if \"ai\" in title.lower() and \"game\" in title.lower():\n",
    "        tc_results.append({\"title\": title, \"link\": href})\n",
    "\n",
    "print(f\"✅ TechCrunch articles collected: {len(tc_results)}\")\n",
    "df2 = pd.DataFrame(tc_results, columns=[\"title\", \"link\"])\n",
    "file2 = \"techcrunch_ai_game_articles.xlsx\"\n",
    "df2.to_excel(file2, index=False)\n",
    "print(f\"✅ Saved to '{file2}'\")\n",
    "\n",
    "driver.quit()  # Close browser when done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cadd5c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️  Opening: https://www.gamedeveloper.com/\n",
      "   → Candidate links: 1\n",
      "▶️  Opening: https://venturebeat.com/category/game-development/\n",
      "   ⚠️ Timeout for selector h2.article__title a, fallback to partial link text\n",
      "   → Candidate links: 2\n",
      "▶️  Opening: https://www.developer-tech.com/categories/developer-gaming/\n",
      "   → Candidate links: 5\n",
      "▶️  Opening: https://techcrunch.com/\n",
      "   ⚠️ Timeout loading TechCrunch selector, trying all links\n",
      "   → TechCrunch candidate links: 333\n",
      "✅ Total 8 articles saved to 'all_ai_game_articles.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# 0) pip install selenium webdriver-manager pandas openpyxl\n",
    "\n",
    "# 1) ChromeDriver 준비 & 옵션\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--headless\")\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "results = []\n",
    "seen_links = set()\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# Part 1: GDC 계열 3개 사이트 (\"Generative AI\" 또는 \"AI\")\n",
    "# ──────────────────────────────────────────────────────────\n",
    "gdc_sites = [\n",
    "    {\"url\": \"https://www.gamedeveloper.com/\", \n",
    "     \"mode\": \"partial\", \"selector\": None},\n",
    "    {\"url\": \"https://venturebeat.com/category/game-development/\", \n",
    "     \"mode\": \"css\", \n",
    "     \"selector\": \"h2.article__title a\"},\n",
    "    {\"url\": \"https://www.developer-tech.com/categories/developer-gaming/\", \n",
    "     \"mode\": \"partial\", \"selector\": None},\n",
    "]\n",
    "gdc_keywords = [\"Generative AI\", \"AI\"]\n",
    "\n",
    "for site in gdc_sites:\n",
    "    print(f\"▶️  Opening: {site['url']}\")\n",
    "    driver.get(site[\"url\"])\n",
    "    # optional: scroll to load more\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    elements = []\n",
    "    if site[\"mode\"] == \"css\":\n",
    "        try:\n",
    "            wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, site[\"selector\"])))\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, site[\"selector\"])\n",
    "        except TimeoutException:\n",
    "            print(f\"   ⚠️ Timeout for selector {site['selector']}, fallback to partial link text\")\n",
    "            # fallback: partial link text for each keyword\n",
    "            for kw in gdc_keywords:\n",
    "                elements += driver.find_elements(By.PARTIAL_LINK_TEXT, kw)\n",
    "    else:\n",
    "        # 직접 partial link text\n",
    "        for kw in gdc_keywords:\n",
    "            elements += driver.find_elements(By.PARTIAL_LINK_TEXT, kw)\n",
    "\n",
    "    print(f\"   → Candidate links: {len(elements)}\")\n",
    "    for a in elements:\n",
    "        title = a.text.strip()\n",
    "        href  = a.get_attribute(\"href\") or \"\"\n",
    "        if not href or href in seen_links:\n",
    "            continue\n",
    "        if any(kw.lower() in title.lower() for kw in gdc_keywords):\n",
    "            seen_links.add(href)\n",
    "            keyword = next(kw for kw in gdc_keywords if kw.lower() in title.lower())\n",
    "            results.append({\n",
    "                \"source\": site[\"url\"],\n",
    "                \"keyword\": keyword,\n",
    "                \"title\": title,\n",
    "                \"link\": href\n",
    "            })\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# Part 2: TechCrunch (\"AI\" & \"Game\")\n",
    "# ──────────────────────────────────────────────────────────\n",
    "tc_url = \"https://techcrunch.com/\"\n",
    "print(f\"▶️  Opening: {tc_url}\")\n",
    "driver.get(tc_url)\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(2)\n",
    "\n",
    "tc_selector = \"h2.post-block__title a\"\n",
    "try:\n",
    "    wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, tc_selector)))\n",
    "    tc_links = driver.find_elements(By.CSS_SELECTOR, tc_selector)\n",
    "except TimeoutException:\n",
    "    print(f\"   ⚠️ Timeout loading TechCrunch selector, trying all links\")\n",
    "    tc_links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "print(f\"   → TechCrunch candidate links: {len(tc_links)}\")\n",
    "for a in tc_links:\n",
    "    title = a.text.strip()\n",
    "    href  = a.get_attribute(\"href\") or \"\"\n",
    "    if not href or href in seen_links:\n",
    "        continue\n",
    "    if \"ai\" in title.lower() and \"game\" in title.lower():\n",
    "        seen_links.add(href)\n",
    "        results.append({\n",
    "            \"source\": tc_url,\n",
    "            \"keyword\": \"AI & Game\",\n",
    "            \"title\": title,\n",
    "            \"link\": href\n",
    "        })\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# Part 3: 합쳐서 엑셀에 저장\n",
    "# ──────────────────────────────────────────────────────────\n",
    "df = pd.DataFrame(results, columns=[\"source\", \"keyword\", \"title\", \"link\"])\n",
    "out_file = \"all_ai_game_articles.xlsx\"\n",
    "df.to_excel(out_file, index=False)\n",
    "print(f\"✅ Total {len(df)} articles saved to '{out_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb084a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Loading: https://www.gamedeveloper.com/page/1/\n",
      "   ⚠️ Timeout on h3.entry-title a, fallback to partial link text\n",
      "   Found 0 candidates\n",
      "▶️ Loading: https://www.gamedeveloper.com/page/2/\n",
      "   ⚠️ Timeout on h3.entry-title a, fallback to partial link text\n",
      "   Found 0 candidates\n",
      "▶️ Loading: https://www.gamedeveloper.com/page/3/\n",
      "   ⚠️ Timeout on h3.entry-title a, fallback to partial link text\n",
      "   Found 0 candidates\n",
      "▶️ Loading: https://venturebeat.com/category/game-development/page/1/\n",
      "   ⚠️ Timeout on h2.article__title a, fallback to partial link text\n",
      "   Found 2 candidates\n",
      "▶️ Loading: https://venturebeat.com/category/game-development/page/2/\n",
      "   ⚠️ Timeout on h2.article__title a, fallback to partial link text\n",
      "   Found 3 candidates\n",
      "▶️ Loading: https://venturebeat.com/category/game-development/page/3/\n",
      "   ⚠️ Timeout on h2.article__title a, fallback to partial link text\n",
      "   Found 9 candidates\n",
      "▶️ Loading: https://www.developer-tech.com/categories/developer-gaming/page/1/\n",
      "   ⚠️ Timeout on h3.node-title a, fallback to partial link text\n",
      "   Found 5 candidates\n",
      "▶️ Loading: https://www.developer-tech.com/categories/developer-gaming/page/2/\n",
      "   ⚠️ Timeout on h3.node-title a, fallback to partial link text\n",
      "   Found 4 candidates\n",
      "▶️ Loading: https://www.developer-tech.com/categories/developer-gaming/page/3/\n",
      "   ⚠️ Timeout on h3.node-title a, fallback to partial link text\n",
      "   Found 5 candidates\n",
      "▶️ Parsing TechCrunch RSS...\n",
      "✅ Saved 0 articles to 'all_ai_game_articles.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# UPDATE \n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Unified scraper for:\n",
    "1. GDC sites (gamedeveloper.com, venturebeat.com, developer-tech.com) collecting \"Generative AI\" and \"AI\" articles over first 3 pages.\n",
    "2. TechCrunch RSS feed to collect articles containing both \"AI\" and \"Game\".\n",
    "Saves all results to a single Excel file: all_ai_game_articles.xlsx\n",
    "\"\"\"\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import feedparser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# 0) Ensure dependencies:\n",
    "#    pip install selenium webdriver-manager pandas openpyxl feedparser\n",
    "\n",
    "# 1) Setup Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--headless\")  # Uncomment to run headless\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "results = []\n",
    "seen_links = set()\n",
    "\n",
    "# ──────────────────────────────────────\n",
    "# Part 1: GDC sites pagination (pages 1-3)\n",
    "# ──────────────────────────────────────\n",
    "gdc_sites = [\n",
    "    {\"url\": \"https://www.gamedeveloper.com\", \"mode\": \"css\", \"selector\": \"h3.entry-title a\"},\n",
    "    {\"url\": \"https://venturebeat.com/category/game-development\", \"mode\": \"css\", \"selector\": \"h2.article__title a\"},\n",
    "    {\"url\": \"https://www.developer-tech.com/categories/developer-gaming\", \"mode\": \"css\", \"selector\": \"h3.node-title a\"},\n",
    "]\n",
    "gdc_keywords = [\"Generative AI\", \"AI\"]\n",
    "\n",
    "for site in gdc_sites:\n",
    "    base = site[\"url\"].rstrip(\"/\")\n",
    "    for page in range(1, 4):  # pages 1,2,3\n",
    "        page_url = f\"{base}/page/{page}/\"\n",
    "        print(f\"▶️ Loading: {page_url}\")\n",
    "        driver.get(page_url)\n",
    "        # scroll multiple times to load dynamic content\n",
    "        for _ in range(3):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "        # wait until at least 5 elements appear, else fallback\n",
    "        selector = site[\"selector\"]\n",
    "        elems = []\n",
    "        try:\n",
    "            wait.until(lambda d: len(d.find_elements(By.CSS_SELECTOR, selector)) >= 5)\n",
    "            elems = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "        except TimeoutException:\n",
    "            print(f\"   ⚠️ Timeout on {selector}, fallback to partial link text\")\n",
    "            for kw in gdc_keywords:\n",
    "                elems.extend(driver.find_elements(By.PARTIAL_LINK_TEXT, kw))\n",
    "\n",
    "        print(f\"   Found {len(elems)} candidates\")\n",
    "        for a in elems:\n",
    "            title = a.text.strip()\n",
    "            link = a.get_attribute(\"href\") or \"\"\n",
    "            # filter only site-specific and new\n",
    "            if not link.startswith(base) or link in seen_links:\n",
    "                continue\n",
    "            if any(kw.lower() in title.lower() for kw in gdc_keywords):\n",
    "                seen_links.add(link)\n",
    "                keyword = next(kw for kw in gdc_keywords if kw.lower() in title.lower())\n",
    "                results.append({\n",
    "                    \"source\": base,\n",
    "                    \"keyword\": keyword,\n",
    "                    \"title\": title,\n",
    "                    \"link\": link\n",
    "                })\n",
    "\n",
    "# ──────────────────────────────────────\n",
    "# Part 2: TechCrunch via RSS feed\n",
    "# ──────────────────────────────────────\n",
    "print(\"▶️ Parsing TechCrunch RSS...\")\n",
    "feed = feedparser.parse(\"https://techcrunch.com/feed/\")\n",
    "for entry in feed.entries:\n",
    "    title = entry.get(\"title\", \"\").strip()\n",
    "    link = entry.get(\"link\", \"\").strip()\n",
    "    if link in seen_links:\n",
    "        continue\n",
    "    if \"ai\" in title.lower() and \"game\" in title.lower():\n",
    "        seen_links.add(link)\n",
    "        results.append({\n",
    "            \"source\": \"TechCrunch\",\n",
    "            \"keyword\": \"AI & Game\",\n",
    "            \"title\": title,\n",
    "            \"link\": link\n",
    "        })\n",
    "\n",
    "# cleanup\n",
    "driver.quit()\n",
    "\n",
    "# ──────────────────────────────────────\n",
    "# Save to single Excel file\n",
    "# ──────────────────────────────────────\n",
    "df = pd.DataFrame(results, columns=[\"source\", \"keyword\", \"title\", \"link\"])\n",
    "out_file = \"all_ai_game_articles.xlsx\"\n",
    "df.to_excel(out_file, index=False)\n",
    "print(f\"✅ Saved {len(df)} articles to '{out_file}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WK3_class310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
